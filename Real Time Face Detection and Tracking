Project-Details
===============

Project Title:      Real-Time Face Detection And Tracking

Author:             Sachin Vishwanath

ABSTRACT:

Face detection and tracking has been an important and active research field because it
offers many applications, especially in video surveillance, biometrics, or video coding. The face detection algorithm involved color-based skin segmentation and image filtering. The face location was determined by calculating the centroid of the
detected region. A software version of the algorithm was independently implemented and
tested on still pictures in MATLAB. All calculation of the hardware implementation was done in real time with minimal
computational effort, thus suitable for power-limited applications.

INTRODUCTION :

Face detection and tracking is the process of determining whether or not a face is present in
an image. Unlike face recognition—which distinguishes different human faces, face detection
only indicates whether or not a face is present in an image. In addition, face tracking
determines the exact location of the face. Face detection and tracking has been an active
research area for a long time because it is the initial important step in many different
applications, such as video surveillance, face recognition, image enhancement, video
coding, and energy conservation. The applicability of face detection in energy conservation
is not as obvious as in other applications. However, it is interesting to learn how a face
detection and tracking system allows power and energy to be saved. Suppose one is
watching a television and working on other tasks simultaneously. The face detection system
is for checking whether or not the person is looking directly at the TV. If the person is not
directly looking at the TV within some time period (i.e. 20 minutes), the TV’s brightness is
reduced to save energy. When the person turns back to look at the TV, the TV’s brightness
can be increased back to original. In addition, if the person looks away for too long (i.e.
more than one hour), then the TV will be automatically turned off.
Different approaches to detect and track human faces—including feature-based,
appearance-based, and color-based have been actively researched and published in
literature. The feature-based approach detects a human’s face based on human facial
features—such as eyes and nose. Because of its complexity, this method requires lots of
computing and memory resources. Although compared to other methods this one gives
higher accuracy rate, it is not suitable for power-limited devices. Hence, a color-based
algorithm is more reasonable for applications that require low computational effort. In
general, each method has its own advantages and disadvantages. More complex algorithm
typically gives very high accuracy rate but also requires lots of computing resources.

CODE :


%%Read original image and get its size%%
face_original = imread('image08.png');
size_img = size(face_original);
r = 1; g = 2; b = 3;
y = 1; u = 2; v = 3;
%%YUV Conversion%%
face_yuv = face_original;
for i = 1:size_img(1)
for j = 1:size_img(2)
face_yuv(i, j, y) = (face_original(i, j, r) + 2*face_original(i, j,
g) + face_original(i, j, b)) / 4;
face_yuv(i, j, u) = face_original(i, j, r) - face_original(i, j, g);
face_yuv(i, j, v) = face_original(i, j, b) - face_original(i, j, g);
end
end
%%Skin segmentation%%
face_detected = face_original;
for i = 1:size_img(1)
for j = 1:size_img(2)
%U range was found based on experiments
if face_yuv(i, j, u) > 20 && face_yuv(i, j, u) < 74
%Set suspected face regions to 1
face_detected(i, j, r) = 255;
face_detected(i, j, g) = 255;
face_detected(i, j, b) = 255;
else
%Set non-face regions to 0
face_detected(i, j, r) = 0;
face_detected(i, j, g) = 0;
face_detected(i, j, b) = 0;
end
end
end
%%Convert image into the BW format; the image itself stays the same, only the
format is changed%%
face_detected = im2bw(face_detected);
%%Erode noise%%
face_imerode = imerode(face_detected, strel('square', 3));
36
%%Fill in holes to get fully connected face regions%%
face_imfill = imfill(face_imerode, 'holes');
%%Label each connected region in the BW image%%
[L, n] = bwlabel(face_imfill); %n gives us #connected objects
face_region = regionprops(L, 'Area', 'BoundingBox');
face_area = [face_region.Area]; %contains areas of all the filled regions
%%Filter out regions whose areas are less than 26% largest area (supposedly a
face area)%%
face_idx = find(face_area > (.26)*max(face_area)); %only shows indices of
regions that are faces
face_shown = ismember(L, face_idx);
%%Face areas vs. box areas%%
fprintf('Ratio between face area and box area \n');
for n = 1:length(face_idx)
idx = face_idx(n);
area_face(n) = face_region(idx).Area;
area_box(n) =
face_region(idx).BoundingBox(3)*face_region(idx).BoundingBox(4);
ratio(n) = area_face/area_box;
end
ratio
%%Compute the coordinates of each face region%%
for n = 1:length(face_idx)
idx = face_idx(n);
face_region(idx).BoundingBox;
xmin = round(face_region(idx).BoundingBox(1));
ymin = round(face_region(idx).BoundingBox(2));
xmax =
round(face_region(idx).BoundingBox(1)+face_region(idx).BoundingBox(3));
ymax =
round(face_region(idx).BoundingBox(2)+face_region(idx).BoundingBox(4));
%%Draw a box around each face found%%
for i = xmin:xmax
face_original(ymin, i, r) = 255;
face_original(ymin, i, g) = 0;
face_original(ymin, i, b) = 0;
end
for i = xmin:xmax
face_original(ymax, i, r) = 255;
face_original(ymax, i, g) = 0;
face_original(ymax, i, b) = 0;
end
for j = ymin:ymax
face_original(j, xmin, r) = 255;
face_original(j, xmin, g) = 0;
face_original(j, xmin, b) = 0;
end
for j = ymin:ymax
face_original(j, xmax, r) = 255;
face_original(j, xmax, g) = 0;
face_original(j, xmax, b) = 0;
end
end
%imshow(face_original), title ('Original Image')
imshow(face_detected), title ('Raw Segmentation Result')
figure, imshow(face_imerode), title ('Eroded Result')
figure, imshow(face_imfill), title ('Filled Regions')
figure, imshow(face_shown), title ('Final Result')
%%Compute centroids of the face regions%%
s = regionprops(face_shown, 'Centroid');
centroids = cat(1, s.Centroid); %cat puts all the s.Centroid values into a
matrix
figure, imshow(face_original), title('Detection Result'), xlabel (['#faces
found: ', num2str(length(face_idx))])
hold on
plot(centroids(:,1), centroids(:,2), 'b*', 'MarkerSize', 10)
hold off



